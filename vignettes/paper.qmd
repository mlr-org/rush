---
title: "rush - A Database-Centric Architecture for Distributed Computing"
format: html
bibliography: references.bib
---

<!--
What journal is this for?
- JSS
- JMLR
- Data Mining and Knowledge Discovery
- R Journal
-->

```{r}
#| include: false
library(rush)
library(here)
here::i_am("vignettes/paper.qmd")

r = redux::hiredis()
r$FLUSHDB()
options(datatable.prettyprint.char = 10L)
```

# Abstract {#sec-abstract}

Distributed computing is a powerful tool for solving large-scale problems.
However, relying on a central process to generate tasks becomes a bottleneck in large-scale problems.
We present rush, a package for asynchronous and distributed computing in R.
Employing a database centric model, rush enables workers to communicate over a shared Redis database.
This architecture allows workers to generate and evaluate tasks independently, eliminating central coordination bottlenecks.
Aiming for minimal overhead per task (~0.5 ms), rush features robust error handling with automatic detection of lost workers, and an efficient caching mechanism that minimizes database operations.
Rush integrates seamlessly with the mlr3 ecosystem, powering asynchronous optimization in the bbotk and mlr3tuning packages.
We demonstrate the usability of rush by implementing asynchronous distributed Bayesian optimization.
Benchmarks show that rush scales efficiently to over 1024 workers while maintaining high CPU utilization.

# Introduction {#sec-introduction}

Distributed computing is a powerful tool for solving large-scale problems in R, including black-box optimization and hyperparameter tuning.
Ever-increasing amounts of data and computational expensive algorithms require work to be distributed across many computers.
Traditional approaches to parallel computing in R, such as the `parallel` and `future` packages, follow a controller-worker model where a central process distributes tasks to workers and collects results.
While effective for many use cases, this architecture introduces a coordination bottleneck: the central controller must generate all tasks, track their status, and aggregate results.
For optimization algorithms that require rapid iteration and asynchronous task generation such as Bayesian optimization [@egele2023] and hyperband [@li2020] this bottleneck limits scalability.

Recent packages like `batchtools` and `crew` address distributed computing on high-performance clusters but incur significant overhead per task, making them unsuitable for workloads involving many fast-running evaluations.
The `rrq` package reduces this overhead by using Redis as a task queue, but still relies on centralized task distribution.

We present rush, a package for asynchronous and distributed computing in R.
Unlike existing solutions, rush eliminates the central controller by allowing workers to communicate over a shared Redis database.
This enables a decentralized architecture where workers can independently generate, evaluate, and share tasks without central coordination.
Rush features low overhead per task (~0.5 ms), robust error handling with automatic detection of lost workers, and an efficient caching mechanism that minimizes database operations.
Rush integrates seamlessly with the mlr3 ecosystem, powering asynchronous optimization in the bbotk and mlr3tuning packages.
We demonstrate the usability of rush by implementing asynchronous distributed Bayesian optimization.
Benchmarks show that rush scales efficiently to over 1024 workers while maintaining high CPU utilization.

rush allows researchers to develop new distributed optimization algorithms and empowers end users to solve large-scale problems with minimal effort.

## Related Work {#sec-related-work}

As multi-core processors became commonplace in the 2000s, there was a growing need to utilize these resources effectively for computational tasks in R.
The first packages to address this need were `snow` [@tierney2021] and `multicore`.
With R version 2.14.0 (released in 2011), parallel computing capabilities were integrated into the base R system through the `parallel` package.
The functions `parallel::mclapply()` and `parallel::parLapply()` are parallel versions of the `lapply()` function for multicore and cluster computing, respectively.
Both functions are widely used in R packages but have some limitations.
The R session is blocked until all tasks are finished and it is not possible to retrieve partial results.
Moreover, load balancing can be an issue when the tasks have different runtimes.

The landscape further evolved with the release of the `future` [@bengtsson2021] package in 2016, which provided a unified and flexible parallel computing interface in R, supporting various backends such as `multisession`, `multicore`, and `callr`.
The `future.apply` package implements parallel versions of the `*apply()` family functions, compatible with the `future` backends.

With the rise of high-performance computing (HPC) clusters, the `batchtools` package was developed to facilitate the execution of long-running tasks on these systems.
The communication between the main process and the workers runs completely over the file system.
A notable feature of the package is the assistance in conducting large-scale computer experiments.
A more recent development in distributed computing is the `crew` package.
The package is designed for long-running tasks in distributed systems, ranging from traditional high-performance clusters to cloud computing platforms.
A drawback of both systems is the high overhead per task.

The `rrq` package is a task queue system for R using Redis.
It addresses the limitations of the packages by providing a non-blocking interface to parallel computing and keeping the overhead per task low.
The package allows non-interacting queues with priority levels within a queue and dependencies among tasks.
The package has an advanced error-handling mechanism, heavily influencing the heartbeat mechanism of `rush`.

<!-- `rush` aligns closely with `rrq` but differentiates itself with its integration into our optimization packages packages `botk` and `mlr3tuning`.
This includes a data structure in Redis that can be efficiently converted to a `"data.table::data.table()"` and a cache mechanism that minimizes the number of read and write operations in the R session.
Moreover, the start of workers with minimal user configuration is integrated with the `"processx"` package.
Looking ahead, rush allows a decentralized network architecture devoid of a central controller. -->

# General Structure of Rush {#sec-general-structure}

A Rush network consists of multiple workers that communicate via a shared Redis database.
Each worker evaluates tasks and pushes the corresponding results back to the database.

![The architecture of a rush network. A hexagon represents a worker and the rectangle represent the Redis database. The worker loop creates a task `T` and evaluates it on the objective function `f` and pushes the output `y`.](network.png){#fig-rush-network width=100%}

We illustrate the basic functionality of Rush using an example optimization problem based on the Branin function.

$$f(x_1,x_2)=\left(x_2-\frac{5.1}{4\pi^2}x_1^2+\frac{5}{\pi}x_1-6\right)^2 +10\left(1-\frac{1}{8\pi}\right)\cos(x_1)+10$$

The function is optimized over the domain $x_1 \in [-5, 10]$ and $x_2 \in [0, 15]$, as shown in Figure @fig-branin.
The Branin function serves as a toy benchmark for optimization that is fast to evaluate yet sufficiently nontrivial.

![Branin function](branin.png){#fig-branin width=100%}


```{r}
branin = function(x1, x2) {
  (x2 - 5.1 / (4 * pi^2) * x1^2 + 5 / pi * x1 - 6)^2 + 10 * (1 - 1 / (8 * pi)) * cos(x1) + 10
}
```

## Worker Loop

We define the worker_loop function, which is executed on each worker.
The function repeatedly creates tasks, evaluates them, and sends the results to the Redis database.
It takes a single argument, a RushWorker object, which manages communication with Redis.
In this example, each worker samples a random point, constructs a task, evaluates it using the Branin function, and submits the result.
The optimization terminates after 100 tasks have been evaluated.

```{r rush-003}
library(rush)

wl_random_search = function(rush) {

  while(rush$n_finished_tasks < 100) {

    xs = list(x1 = runif(1, -5, 10), x2 = runif(1, 0, 15))
    key = rush$push_running_tasks(xss = list(xs))

    ys = list(y = branin(xs$x1, xs$x2))
    rush$push_results(key, yss = list(ys))
  }
}
```

The most important methods of the `RushWorker` class are `$push_running_tasks()` and `$push_results()`.
The `$push_running_tasks()` method creates a new task in the Redis database.
Because the task is scheduled for immediate evaluation, it is marked as running.
The `$push_running_tasks()` method returns a unique key that is used to identify the task.

The `$push_results()` method pushes the corresponding results back to the Redis database.
It takes the task key and a list of result values as arguments.

Marking a task as running is not essential for random search.
However, it is crucial for more sophisticated algorithms that use information about other workers’ tasks to decide which task to evaluate next.
For example, Bayesian optimization algorithms select new evaluation points that are farther from previously sampled points in order to explore the search space more effectively.
The `$n_finished_tasks` field indicates how many tasks have been completed and is used to terminate the worker loop.

## Tasks

Tasks are the basic units through which workers exchange information.
The main components of a task are its key, computational state, input (`xs`), and output (`ys`).
The key is a unique identifier for the task.
It is used to reference the task in the Redis database.

The four possible computational states are `"running"`, `"finished"`, `"failed"`, and `"queued"`.
The `$push_running_tasks()` method marks a task as `"running"` and returns its key.
The `$push_results()` method marks a task as `"finished"` and stores the associated result.
Failed tasks can be marked as `"failed"` using the `$push_failed()` method.
Error handling must be implemented explicitly in the worker loop (see @sec-error-handling for details).
Tasks can also be pushed to a queue using the `$push_tasks()` method, which sets their state to `"queued"`.

The input `xs` and output `ys` are lists that may contain arbitrary data.
The methods of the `RushWorker` can operate on multiple tasks simultaneously.
For this reason, `xxs` and `yss` denote lists of inputs and outputs, respectively.

## Manager

The `rush` manager is responsible for starting, monitoring, and stopping workers within the network.
It is initialized using the `rsh()` function, which requires a network identifier and a `config` argument.
The `config` argument specifies a configuration file used to connect to the Redis database via the `redux` package.

```{r rush-004}
library(rush)

config = redux::redis_config()

rush = rsh(
  network = "test-random-search",
  config = config)
```

Workers can be started using the `$start_local_workers()` method, which accepts the worker loop and the number of workers as arguments.
By default, workers are started locally using the `processx` package.

```{r rush-005}
rush$start_local_workers(
  worker_loop = wl_random_search,
  branin = branin,
  n_workers = 4)

rush
```

The optimization completes quickly and the results can then be retrieved.
The `$fetch_finished_tasks()` method fetches all finished tasks from the database.
It returns a `data.table()` containing the task key, input, and result.
The `pid` and `worker_id` columns store additional information recorded when each task is created.
The `worker_id` identifies the worker that evaluated the task, and the `pid` corresponds to the process identifier of that worker.
Further auxiliary information can be passed as `list`s to the `$push_running_tasks()` and `$push_results()` methods via the `extra` argument.

```{r rush-006}
#| include: false
Sys.sleep(5)
```

```{r rush-007}
#rush$fetch_finished_tasks()[order(y)]
```

The `rush` controller displays the number of running workers and the number of tasks in each state.
In this example, 103 tasks are marked as finished and all workers have stopped.
This number slightly exceeds 100 because workers check the stopping condition independently.
If several workers evaluate the condition at approximately the same time, for example when 99 tasks are finished, they may all create new tasks before detecting that the limit has been reached.
Additionally, tasks may continue to be created while the 100th task is still being evaluated.

```{r rush-008}
rush
```

The workers can be stopped and the database reset using the `$reset()` method.

```{r rush-009}
rush$reset()

rush
```


## Data Storage

Rush stores all data in a Redis database.
Redis is an open-source, in-memory key-value store commonly used as a database, cache, and message broker.
It is valued for extremely low latency and supports multiple data structures such as strings, hashes, lists and sets.
Rush uses different data structures of Redis to store the data.

Redis hashes are a data structure for storing associative field–value pairs under a single key.
They are optimized for memory efficiency and fast access to structured data.
This makes them suitable for representing the input, output and meta information of tasks.
The key of the hash identifies the task in Redis and rush.

```
key : xs | ys | xs_extra
```

The field-value pairs are written by different methods, e.g. `$push_running_tasks()` writes `xs` and `$push_results()` writes `ys`.
The values of the fields are serialized lists or atomic values e.g. unserializing `xs` gives `list(x1 = 1, x2 = 2)`
This data structure allows quick converting of a hash into a row and joining multiple hashes into a table.

```
| key | x1 | x2 | y | timestamp |
| 1.. |  3 |  4 | 7 |  12:04:11 |
| 2.. |  1 |  4 | 5 |  12:04:12 |
| 3.. |  1 |  1 | 2 |  12:04:13 |
```

Redis sets are an unordered collection of unique elements associated with a single key.
They enforce uniqueness automatically and support efficient membership tests.
Sets are used to store the state of tasks.
For example, all running tasks are stored in the `"running_tasks"` set.

Redis lists are ordered collections of elements stored as linked lists under a single key.
They support efficient insertion and removal at both the head and the tail, enabling queues and event logs where ordering is significant.
Finished and queued tasks are stored in a list.
Using lists for the queue is an obvious choice because it allows to push and pop tasks from the head and the tail.
Storing the finished tasks in a list gives them an order by time.
This allows to cheaply get the latest results and cache the finished tasks.

# Advanced Features of Rush

## Queues

Sometimes it is advantageous to create tasks in central process and push them to the workers.
This avoids to coordinate which worker evaluates which task.

The queue system works by pushing and popping tasks from a queue.
The `$push_task()` method creates new tasks and pushes them to the queue.
In this example, we create 25 tasks and push them to the queue.

```{r rush-016}
xss = replicate(25, list(x1 = runif(1, -5, 10), x2 = runif(1, 0, 15)), simplify = FALSE)

rush$push_tasks(xss = xss)

rush
```

We see 25 queued tasks in the database.
To retrieve the tasks from the queue, we need to implement the `$pop_task()` method in the worker loop.

```{r rush-017}
wl_queue = function(rush) {
  repeat {
    task = rush$pop_task()
    if (is.null(task)) break
    ys = list(y = branin(task$xs$x1, task$xs$x2))
    rush$push_results(task$key, yss = list(ys))
  }
}
```

The `$pop_task()` method pops a task from the queue and marks it as running.
It returns the task or `NULL` if the queue is empty.
We use this to stop the worker loop when the queue is empty.

## Error Handling {#sec-error-handling}

rush is equipped with an advanced error-handling mechanism designed to manage and mitigate errors encountered during the execution of tasks.
It adeptly handles a range of error scenarios, from standard R errors to more complex issues such as segmentation faults and network errors.

Within the worker loop, users are responsible for catching errors and marking the corresponding task as `"failed"` using the `$push_failed()` method.

```{r rush-018}
wl_error = function(rush) {

  while(rush$n_finished_tasks < 100) {

    xs = list(x1 = runif(1, -5, 10), x2 = runif(1, 0, 15))
    key = rush$push_running_tasks(xss = list(xs))

    tryCatch({
      ys = list(y = branin(xs$x1, xs$x2))
      rush$push_results(key, yss = list(ys))
    }, error = function(e) {
      condition = list(message = e$message)
      rush$push_failed(key, conditions = list(condition))
    })
  }
}
```

The rush package provides mechanisms to address situations in which workers fail due to crashes or lost connections.
Such failures may result in tasks remaining in the "running" state indefinitely.
The package offers the `$detect_lost_workers()` method, which is designed to identify and manage these occurrences.
The controller updates the state of the worker to `"lost"`.

This method works for workers started with `$start_local_workers()` and `$start_remote_workers()`.
Workers started with `$worker_script()` must be started with a heartbeat mechanism
The mechanism consists of a heartbeat key with a set expiration timeout and a dedicated heartbeat process that refreshes the timeout periodically.
The heartbeat process is started with `callr` and is linked to the main process of the worker.
In the event of a worker's failure, the associated heartbeat process also ceases to function, thus halting the renewal of the timeout.
The absence of the heartbeat key acts as an indicator to the controller that the worker is no longer operational.
Consequently, the controller updates the worker's status to `"lost"`.

Heartbeats are initiated upon worker startup by specifying the `heartbeat_period` and `heartbeat_expire` parameters.
The `heartbeat_period` defines the frequency at which the heartbeat process will update the timeout.
The `heartbeat_expire` sets the duration, in seconds, before the heartbeat key expires.
The expiration time should be set to a value greater than the heartbeat period to ensure that the heartbeat process has sufficient time to refresh the timeout.

```{r controller-054}
rush$worker_script(
  worker_loop = wl_random_search,
  heartbeat_period = 1,
  heartbeat_expire = 3)
```

The heartbeat process is also the only way to kill a script worker.
The `$stop_workers(type = "kill")` method pushes a kill signal to the heartbeat process.
The heartbeat process terminates the main process of the worker.

Additionally, the Redis database can be saved to disk periodically.

## Log Messages

Workers record all messages generated using the `lgr` package to the database.
The `lgr_thresholds` argument of `$start_local_workers()` specifies the logging level for each logger, e.g. `c("mlr3/rush" = "debug")`.
While enabling log message storage introduces a minor performance overhead, it is valuable for debugging purposes.
By default, log messages are not stored.

## Debugging

* If all of this fails, the user can manually debug the worker loop.
* Output and message logs can be written to files by specifying the `message_log` and `output_log` arguments.


# Tutorial

We implement Asynchronous Distributed Bayesian Optimization (ADBO) [@egele_2023] next.
This example shows how workers use information about running and finished tasks and introduces task queues.
ADBO runs sequential [Bayesian optimization](https://mlr3book.mlr-org.com/chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html#sec-bayesian-optimization) on multiple workers in parallel.
Each worker maintains its own surrogate model (a random forest) and selects the next hyperparameter configuration by maximizing the upper confidence bounds acquisition function.
To promote a vathe optimization of algorithmsrying exploration-exploitation tradeoff between the workers, the acquisition functions are initialized with different lambda values ranging from 0.1 to 10.
When a worker completes an evaluation, it asynchronously sends the result to its peers via a Redis data base; each worker then updates its local model with this shared information.
This decentralized design enables workers to proceed independently; eliminating the need for a central coordinator that could become a bottleneck in large-scale optimization scenarios.

# Benchmarks

## Bayesian Optimization

### Setup

We compare the performance of BO algorithms on hyperparameter optimization problems.
The first algorithm evaluates a batch of hyperparameter configurations in parallel.
The second algorithm evaluates hyperparameter configurations asynchronously.
The third algorithm proposes new hyperparameter configurations and evaluates them asynchronously.

Each BO experiment runs for 10 minutes and has 448 workers for parallelization.


The benchmark was conducted on linux cluster of the Leibniz Supercomputing Centre (LRZ).
Each node has 112 Intel Xeon (Sapphire Rapids) cores and 488 GiB of memory.







## Setup

The evaluation of fast running tasks is sensible to runtime overhead.
Therefore, we measure the runtime of the core functions of rush in a benchmark.
This includes pushing a task to the database, pushing a result to the database, and fetching finished tasks.
The fetching operation is done with and without caching.
Runtime is reported as median and median absolute deviation (MAD) over 1000 runs.
The runtime is measured with the `microbenchmark` R package.


I want to run benchmark.
The benchmark runs 3 types of Bayesian optimization algorithms:

1. Batch parallel Bayesian optimization `OptimizerMBO`
2. Centralized Bayesian optimization
3. Asynchronous distributed Bayesian optimization `OptimizerABO`

Number 1 and 3 are already implemented.
I need the second one.
The evaluation of the objective should be done asynchronously but the fitting of the surrogate model and the selection of the next task should be done in the central process.
You can use rush for the asynchronous evaluation of the objective.
Also suggest a better name for the algorithm.


The benchmark optimizes eight hyperparameters of the XGBoost learner using the ADBO algorithm on 1024 workers.
The bank marketing dataset, derived from a Portuguese bank’s marketing campaign, includes client demographics, financial details, and previous interactions to predict term deposit subscriptions.
Experiments were conducted on 10 nodes, each with 128 cores, totaling 1,280 workers.
The optimization ran for 30 minutes, consuming 640 CPU hours.
We compute the effective cpu utilization defined as the ratio between the total time spent on training xgboost models and the execution time times the number of workers.

## Results

Pushing a running task to the database is the most frequent operation in rush.
This operation takes 0.5 ms (MAD 0.25 ms) on average.
Pushing a result to the database takes around the same time.
The workers usually fetch new results frequently, so fetching has a build in caching mechanism.
The difference between fetching with and without caching is negligible for a small number of tasks.
However, fetching with caching is much faster when caching more than 1000 tasks, as shown in Figure @fig-fetch-finished-tasks.
The difference grows with the number of tasks fetched.
We fetch one new tasks from the database and the rest from the cache.
Still the runtime increases with the number of tasks fetched.
This is because binding a new row to a data.table gets slower with the total number of rows.

```{r}
#| echo: false
#| fig-cap: |
#|   "Runtime of fetching finished tasks with (red lines) and without (blue lines) caching."
#|   "The x-axis shows the number of tasks fetched from the database."
#|   "The fetching with caching gets one new task from the database and the rest from the cache."
#|   "The fetching without caching gets all tasks from the database."
#| label: fig-fetch-finished-tasks
library(data.table)
library(ggplot2)

gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}

data = fread(here("vignettes/rush_fetch_finished_tasks.csv"))
data_cache = fread(here("vignettes/rush_fetch_cached_tasks.csv"))

data = rbindlist(list(
  data[, list(n_tasks = n_tasks, runtime = median_runtime, benchmark = "fetch_tasks")],
  data_cache[, list(n_tasks = cache_size, runtime = median_runtime, benchmark = "fetch_cached_tasks")]
))

ggplot(data, aes(x = n_tasks, y = runtime, color = benchmark)) +
  scale_x_continuous(trans='log10') +
  #scale_y_continuous(trans='log10') +
  geom_line() +
  geom_point() +
  scale_color_manual(values = gg_color_hue(2), labels = c("with cache", "without cache")) +
  labs(x = "Number of Tasks", y = "Runtime (ms)", color = "Fetching") +
  theme_minimal()
```

The effective cpu utilization


# Discussion and Conclusion

We presented rush, a novel package for distributed computing in R.



#### Glossary

* Parallel computing: The use of multiple processing elements simultaneously for solving a computational problem.
* Distributed computing: Utilizing multiple computers in a network to solve a computational problem.
* Worker: A process that performs tasks as part of a larger computation.
* Computing task: A discrete portion of a larger computational problem, designed to be executed by a worker.
* Redis: An open-source, in-memory data store, used as a database and for inter-process communication.
* Inter-process communication: Set of mechanisms that allow separate processes to exchange data and coordinate their execution.
