---
title: "Benchmark rush"
format:
  html:
    toc: true
    html-math-method: katex
---

```{r setup}
library(rush)
library(data.table)
library(mlr3misc)
library(microbenchmark)

options(width = 200)

lgr::get_logger("rush")$set_threshold("warn")
```

# Push

Push task to queue.

```{r}
config = redux::redis_config()
server = Rush$new("benchmark", config)
server$reset()

xss = list(x1 = 4, x2 = 6)
xss_100 = replicate(100, xss, simplify = FALSE)
xss_10000 = replicate(10000, xss, simplify = FALSE)

microbenchmark(
  push_1 = server$push_tasks(list(xss)),
  push_100 = server$push_tasks(xss_100),
  push_10000 = server$push_tasks(xss_10000),
  times = 100,
  setup = server$reset()
)
```

Pushing a task to the worker takes around 1 ms.
The time grows slower than linearly with the number of tasks.
Probably because of pipelining in redis.
In comparison, starting a worker and serializing for `mlr3::resample()` takes 200 ms.

```{r}
config = redux::redis_config()
server = Rush$new("benchmark", config)
server$reset()

xss = list(x1 = 4, x2 = 6, x3 = 1, x4 = 2)
xss_100 = replicate(100, xss, simplify = FALSE)
xss_10000 = replicate(10000, xss, simplify = FALSE)

microbenchmark(
  push_1 = server$push_tasks(list(xss)),
  push_100 = server$push_tasks(xss_100),
  push_10000 = server$push_tasks(xss_10000),
  times = 100,
  setup = server$reset()
)
```

# Push with Extra

```{r}
xss = list(x1 = 4, x2 = 6)
xss_100 = replicate(100, xss, simplify = FALSE)
xss_10000 = replicate(10000, xss, simplify = FALSE)

microbenchmark(
  push_1 = server$push_tasks(list(xss), list(xss)),
  push_100 = server$push_tasks(xss_100, xss_100),
  push_10000 = server$push_tasks(xss_10000, xss_10000),
  times = 100,
  setup = server$reset()
)
```

# Pop

Pop task from queue.

```{r}
server_1 = Rush$new("benchmark_1", config)
server_100 = Rush$new("benchmark_100", config)
server_10000 = Rush$new("benchmark_10000", config)

xss = list(x1 = 4, x2 = 6)
xss_100 = replicate(100, xss, simplify = FALSE)
xss_10000 = replicate(10000, xss, simplify = FALSE)

setup = function(server, xss) {
  server$reset()
  server$push_tasks(xss)
}

microbenchmark(
  pop_1 = server_1$pop_task(),
  pop_100 = server_100$pop_task(),
  pop_10000 = server_10000$pop_task(),
  times = 10,
  setup = {setup(server_1, list(xss)); setup(server_100, xss_100); setup(server_10000, xss_10000)}
)
```

Pulling a task from the queue takes around 1 ms.
The time is independent of the number of tasks.

# Syncing

Sync results.

```{r}
config = redux::redis_config()
server_1 = Rush$new("benchmark_1", config)
server_100 = Rush$new("benchmark_100", config)
server_10000 = Rush$new("benchmark_10000", config)

xss = list(x1 = 4, x2 = 6)
xss_100 = replicate(100, xss, simplify = FALSE)
xss_10000 = replicate(10000, xss, simplify = FALSE)

setup = function(server, xss) {
  server$reset()
  keys = server$push_tasks(xss)
  server$connector$command(c("SADD", get_private(server)$.get_key("running_tasks"), keys))
  walk(keys, function(key) server$push_result(key, list(y = 10)))
}

microbenchmark(
  sync_1 = server_1$sync_data(),
  sync_100 = server_100$sync_data(),
  sync_10000 = server_10000$sync_data(),
  times = 10,
  setup = {setup(server_1, list(xss)); setup(server_100, xss_100); setup(server_10000, xss_10000)}
)
```

Syncing one result takes about 1 ms, syncing 10,000 result about 150 ms.
The time grows slower than linearly with the number of tasks.
Probably because of pipelining in redis.

# Caching

Sync one result to existing cache.

```{r}
server_1 = Rush$new("benchmark_1", config)
server_100 = Rush$new("benchmark_100", config)
server_10000 = Rush$new("benchmark_10000", config)

xss = list(x1 = 4, x2 = 6)
xss_100 = replicate(100, xss, simplify = FALSE)
xss_10000 = replicate(10000, xss, simplify = FALSE)

setup = function(server, xss) {
  server$reset()
  keys = server$push_tasks(xss)
  server$connector$command(c("SADD", get_private(server)$.get_key("running_tasks"), keys))
  walk(keys, function(key) server$push_result(key, list(y = 10)))
  server$sync_data()
  key = server$push_tasks(xss[1])
  server$connector$command(c("SADD", get_private(server)$.get_key("running_tasks"), keys))
  server$push_result(key[[1]], list(y = 10))
}

setup(server_1, list(xss))

microbenchmark(
  sync_1 = server_1$sync_data(),
  sync_100 = server_100$sync_data(),
  sync_10000 = server_10000$sync_data(),
  times = 1,
  setup = {setup(server_1, list(xss)); setup(server_100, xss_100); setup(server_10000, xss_10000)}
)
```

Syncing one result to an existing cache takes about 1 ms independent of the number of elements in the cache.
Probably due to shallow copy in R.

# List columns

```{r}
size = 100
xdt = data.table(x1 = runif(size), x2 = runif(size))
xss = transpose_list(xdt)
xss_wrapped = map(xss, function(x) list(list(x_domain = x)))
rbindlist(xss_wrapped)

microbenchmark(
  wrap = map(xss, function(x) list(list(x_domain = x))),
  times = 100
)

size = 1000
xdt = data.table(x1 = runif(size), x2 = runif(size))
xss = transpose_list(xdt)
xss_wrapped = map(xss, function(x) list(list(x_domain = x)))
rbindlist(xss_wrapped)

microbenchmark(
  wrap = map(xss, function(x) list(list(x_domain = x))),
  times = 100
)

microbenchmark(
  set(xdt, j = "xss", value = xss),
  times = 100
)
```
